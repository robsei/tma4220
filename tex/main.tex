\documentclass{report}
\usepackage{mathptmx}
\usepackage[round]{natbib}
\usepackage{fullpage}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{mathtools, bm}
\usepackage{amssymb, bm}
\usepackage[hidelinks]{hyperref}

\renewcommand*\d{\mathop{}\!\mathrm{d}}
\renewcommand\phi{\varphi}
\renewcommand\O{\mathcal{O}}

\newcommand\bslash{\symbol{`\\}}

\DeclareMathOperator{\spn}{span}
\DeclareMathOperator{\dom}{dom}

\def\ssq{\subseteq}
\def\N{\mathbb{N}}
\def\R{\mathbb{R}}
\def\T{\mathcal{T}}
\def\iso{\text{iso}}
\def\ani{\text{ani}}
\def\mass{\text{mass}}

\begin{document}

\bibliographystyle{plainnat}
\lstset{language=Matlab}

\title{Heat and Color Flow with Finite Elements}
\author{Obed Afram\footnote{Mat. No. 763619}, Anissa El Keurti\footnote{Mat. No. 998138}, Robert Seidel\footnote{Mat. No. 999321}}
\date{November 2016}
\maketitle

\tableofcontents

\listoftables

\listoffigures

\chapter{Finite Elements and the Poisson Equation}


\section{Gaussian Quadrature}

Gaussian quadrature is one of the popular integration schemes for computing integrals that are not possible to solve analytically. In one dimension the Gaussian quadrature takes the form
\begin{equation}
	\int_{-1}^{1} g(x)\d x\approx\sum_{q=1}^{Nq} \rho_q g(z_q),
\end{equation}
where $N_q$ is the number of integration points, $z_q$ are the Gaussian quadrature points and $\rho_q$ are the associated Gaussian weights. This extends to higher dimensions by
\begin{equation}
	\int_{\hat{\Omega}} g({x}) \d x\approx\sum_{q=1}^{Nq} \rho_q g(z_q),
\end{equation}
and specifying the vector quadrature points $z_q$ as well as integrating over a suitable reference domain $\hat{\Omega}$, e.g. squares or triangles in 2D, tetrahedrons or cubes in 3D.


\subsection{1D quadrature}
We write a MATLAB function \texttt{I = quadrature1D(a,b,Nq,g)}\footnote{All functions mentioned in this report can be found in the code files.} with the following arguments:
\begin{itemize}
	\item $I\in\mathbb{R}$, value of the integral,
	\item $a\in\mathbb{R}$, integration start,
	\item $b\in\mathbb{R}$, integration end,
	\item $N_q \in\mathbb{N}$, number of integration points,
	\item $g: \mathbb{R} \rightarrow \mathbb{R}$ function pointer.
\end{itemize}
We then test the written function by comparing with the analytical solution of the integral
\begin{equation}
	\int_1^2 e^x \d x = (e-1)e \approx 4.6708
\end{equation}
which happens to be the same, as the number of integration points is increased.

\subsection{2D quadrature} 

In higher dimensions, we often map to barycentric coordinates (or area coordinates, as they are known in 2D). The Gauss points are then given as triplets in this coordinate system.

We write a MATLAB function \texttt{I = quadrature2D(p1,p2,p3,Nq,g)} with the following arguments:
\begin{itemize}
	\item $I\in\mathbb{R}$, value of the integral,
	\item $p1\in\mathbb{R}^2$, first corner point of the triangle,
	\item $p2\in\mathbb{R}^2$, second corner point of the triangle,
	\item $p3\in\mathbb{R}^2$, third corner point of the triangle,
	\item $N_q \in{\{1,3,4\}}$, number of integration points,
	\item $g: \mathbb{R}^2 \rightarrow \mathbb{R}$, function pointer.
\end{itemize}
We then verify our function by comparing it with the analytical solution of the integral
\begin{equation}
	\iint \limits_{\Omega} \log (x+y) \d xdy,
\end{equation}
where $\Omega$ is the triangle defined by the corner points $(1, 0)$, $(3, 1)$ and $(3, 2)$. We solve the integral analytically by mapping the coordinates to the barycentric coordinates and compare the results.  

\begin{align}
	N_0 (\xi,\eta)&=1-\xi-\eta\\ 
	N_1 (\xi,\eta)&=\xi\\
	N_2 (\xi,\eta)&=\eta 
\end{align}

\begin{align}
	x&= P(\xi,\eta)= x_0 N_0 +x_1 N_1 +x_2 N_2 = 1+2\xi+2\eta\\
	y&= Q(\xi,\eta)= y_0 N_0 +y_1 N_1 +y_2 N_2 = \xi+2\eta\\ 
	|J| &=2
\end{align}

\begin{align}
	\iint_\Omega \log(x+y) \d xdy
	&= \iint_\Omega \log(P(\xi,\eta), Q(\xi,\eta))  \cdot |J| \d\xi \d\eta\\   
	&= \int_0^1 \int_0^{1-\eta} \log(1+3\xi+4\eta) \cdot 2 \d\xi \d\eta \approx 1.16542
\end{align}
This is approximately the same as the results from our function, with a small error when the number of integration points is increased.

\subsection{3D quadrature}

We now extend the barycentric coordinates to 3 dimensions and tetrahedral elements. We then write a MATLAB function \texttt{I=quadrature3D(p1,p2,p3,p4,Nq,g)}with the following arguments:
\begin{itemize}
	\item $I\in\mathbb{R}$, value of the integral,
	\item $p1\in\mathbb{R}^3$, first corner point of the triangle,
	\item $p2\in\mathbb{R}^3$, second corner point of the triangle,
	\item $p3\in\mathbb{R}^3$, third corner point of the triangle,
	\item $p4\in\mathbb{R}^3$, fourth corner point of the triangle,
	\item $N_q \in{\{1,4,5\}}$, number of integration points,
	\item $g: \mathbb{R}^3 \rightarrow \mathbb{R}$, function pointer.
\end{itemize}

We verify our function by comparing it with the analytical solution of the integral
\begin{equation}
	\iiint \limits_{\Omega} e^x \d x dy  \d z
\end{equation}
where $\Omega$ is the tetrahedron defined by the corner points $(0, 0, 0)$, $(0, 2, 0)$, $(0, 0, 2)$ and $(2, 0, 0)$. We solve the integral analytically by mapping the coordinates to the barycentric coordinates and compare the results with that of the numerical function which happens to be approximately the same. However, there is a little margin of error.  

\begin{align}
	N_0 (\xi,\eta,\zeta)&=1-\xi-\eta-\zeta\\ 
	N_1 (\xi,\eta,\zeta)&=\xi\\
	N_2 (\xi,\eta,\zeta)&=\eta\\
	N_3 (\xi,\eta,\zeta)&=\zeta
\end{align}

\begin{align}
	x&= P(\xi,\eta,\zeta)= x_0 N_0 +x_1 N_1 +x_2 N_2 +x_3 N_3 = 2\xi\\
	y&= Q(\xi,\eta,\zeta)= y_0 N_0 +y_1 N_1 +y_2 N_2 +y_3 N_3  = 2\eta\\ 
	z&= K(\xi,\eta,\zeta)= z_0 N_0 +z_1 N_1 +z_2 N_2 +z_3 N_3  = 2\zeta\\ 
	|J| &=6
\end{align}

\begin{align}
	\iiint_\Omega e^x \d x \d y \d z &= \iiint_\Omega e^{P(\xi,\eta,\zeta), Q(\xi,\eta,\zeta), K(\xi, \eta,\zeta)} \cdot |J| \d\xi \d\eta \d\zeta \\   
	&= \int_0^1 \int_0^{1-\xi} \int_0^{1-\xi-\eta} e^{2\xi} \cdot 6 \d\zeta \d\eta \d\xi \\
	&= \frac{3}{4}(e^2 - 5) \approx 1.79179
\end{align}


\section{Poisson in 2D}

We solve the two-dimensional Poisson problem, given by

\begin{align}
	\nabla^2 u(x,y) &= -f(x,y) \label{poissondirhom1} \\
	u(x,y)|_{\partial\Omega} &= 0 \label{poissondirhom2}
\end{align}
with $f$ given by
\begin{equation}
	f(x,y)=16\pi^2 xy(x^2 + y^2) \sin (2\pi (x^2 + y^2))-24xy\pi \cos (2\pi (x^2 + y^2)).
\end{equation}
The domain $\Omega$ is given by a three-quarter slice of the unit disc. In polar coordinates, we get
\begin{equation}
	\Omega = \{(r,\theta): r\le1 \text{ and } \theta \in [0,3\pi/2]\}.
\end{equation}

\subsection{Analytical solution}

We verify that the expression

\begin{equation} \label{poissonsol}
	u(x,y)=xy \sin (2\pi (x^2 + y^2))
\end{equation}
is a solution to the problem in (\ref{poissondirhom1}-\ref{poissondirhom2}):

\begin{align}
	\nabla^2 u(x,y) =& \frac{\partial^2 u(x,y)}{\partial x^2} + \frac{\partial^2 u(x,y)}{\partial y^2} \\
	=& \frac{\partial}{\partial x}\{y \sin (2\pi (x^2 + y^2)) +4\pi x^2 y \cos (2\pi (x^2 + y^2))\} \\
	& + \frac{\partial}{\partial y}\{x \sin (2\pi (x^2 + y^2)) +4\pi x y^2 \cos (2\pi (x^2 + y^2))\} \\
	=& 12\pi xy \cos (2\pi (x^2 + y^2)) - 16\pi^2 x^3 y\sin (2\pi (x^2 + y^2)) \\
	& + 12\pi xy \cos (2\pi (x^2 + y^2)) - 16\pi^2 x y^3 \sin (2\pi (x^2 + y^2)) \\
	=& -16\pi^2 xy (x^2 + y^2) \sin (2\pi (x^2 + y^2)) + 24\pi xy \cos (2\pi (x^2 + y^2)).
\end{align}


\subsection{Weak formulation}

We start by multiplying equation (\ref{poissondirhom1}) by a test function $v$ and integrate over the domain $\Omega$:
\begin{equation}
-\iint_{\Omega} (\nabla^2 u) v \d x \d y = \iint_{\Omega}fv \d x \d y.
\end{equation}
We apply Green's formula for the Laplacian to the first integral, with the purpose of eliminating the second derivative in order to impose a lower regularity on the solution. We find
\begin{equation}
-\iint_{\Omega} (\Delta u) v \d x \d y = \iint_{\Omega}\nabla u \cdot \nabla v \d x \d y -  \iint_{\partial \Omega} \frac{\partial u}{\partial n} v \d\gamma  
\end{equation}
We can now consider only test functions which vanish at the boundary of the domain, hence the contribution of the boundary terms vanishes. In this way, the equation becomes
\begin{equation}
\iint_{\Omega} \nabla u \cdot \nabla v \d x \d y = \iint_{\Omega}fv \d x \d y.
\end{equation}
We further reduce the equation to the form
\begin{equation}
	a(u,v) = F(v), \forall v \in V.
\end{equation}
with the bilinear functional $a$ and the linear functional $F$ given by
\begin{align}
	a(u,v) &=  \iint_{\Omega} \nabla u \cdot \nabla v \d x \d y, \\
	F(v) &= \iint_{\Omega}fv \d x \d y.
\end{align}
The space $V$ of test functions must therefore be such that if $v \in V$ then $v |_{\partial \Omega} = 0$ and $v$ must be a least once (weakly) differentiable. So, we choose $V = H_0^1(\Omega)$.

\subsection{Galerkin projection}

Instead of searching for a solution u in the entire space V, we look for a solution in a much smaller space $V_h \subset V$. We let $\Omega$ be discretized into $M$ triangles such that our computational
domain is the union of all of these, i.e. $\Omega = \bigcup_{k=1}^M$. Each triangle $K_k$ is then defined by its three corner nodes $x_i$ ($i=1,2,3$) and for each of these nodes exists a corresponding basis function. The space $V_h$ is then defined by
\begin{equation}
	V_h = \{ v \in V: v|_{K_k} \in P_1 (K_k),\ k  = 1,...,M\}
\end{equation}
for which $n \in \N$ basis functions $\{\varphi_i\}_{i=1}^n $ satisfy $V_h = \spn\{\varphi_i\}_{i=1}^n$, $\varphi_j (x_i) = \delta_{ij}$. By searching for a solution $u_h \in V_h$, it is then possible to write this as a weighted sum of the basis functions, i.e. $u_h = \sum_{i=1}^n u_h^i \varphi_i$. We now find $u_h \in V_h$ such that $a(u_h , v) = F(v)$ $\forall v \in V_h$. We arrive at the equations
\begin{align}
	a\left(\sum_{i=1}^n u_h^i \varphi_i , \varphi_j\right) &= F (\varphi_i), \\
	\sum_{i=1}^n a(u_h^i \varphi_i , \varphi_j) &= F (\varphi_i), \\
	\sum_{i=1}^n a(\varphi_i , \varphi_j) u_h^i &= F (\varphi_i),
\end{align}
which is equivalent to the linear system
\begin{equation} \label{poissondirhomlinsys}
	Au = f
\end{equation}
with
\begin{align}
	A &= [A_{ij}] = [a(\varphi_i , \varphi_j)], \\
	u &= [u_h^i], \\
	f &= [f_i] = [F (\varphi_i)].
\end{align}

\subsection{Implementation}

The function \texttt{getSlice} generates the domain $\Omega$. We apply the Gaussian quadrature in the computation and realize the computational work in the function \texttt{poisson2D\_dirichlet}. We compare here three meshes of different sizes (i.e. $n= 50, 500$ and $1000$). We observe from figure \ref{vis:2dpoissondir} that we have the image to be very close to the real solution with a very little margin of error as the number of elements is increased.

\subsubsection{Stiffness matrix}

The stiffness matrix represents the system of linear equations that must be solved in order to ascertain an approximate solution to the differential equation. In order to solve for $u$, we first choose a set of basis functions and then compute the integrals defining the stiffness matrix. We discretized the domain $\Omega$ by some form of mesh generation, wherein it is divided into non-overlapping triangles or quadrilaterals, which are generally referred to as elements. Each triangle is then visited once by the algorithm.

Without the inclusion of boundary conditions, the system (\ref{poissondirhom1}-\ref{poissondirhom2}) does not have a unique solution. Thus, the matrix $A$ is singular as well.

\subsubsection{Right hand side}

In the same manner, we build the right side vector $f$, as we did with $A$.

\subsubsection{Boundary conditions}

We implement homogeneous Dirichlet boundary conditions by deleting the boundary nodes in $A$ and $f$.

\subsection{Verification}

We solve the system (\ref{poissondirhomlinsys}) and then after verification with the analytical solution (\ref{poissonsol}), we observe that the both the solutions are approximately the same, see figure \ref{vis:2dpoissondir}.

\section{Neumann boundary conditions}

We now change the boundary conditions of our problem to
\begin{align}
	\nabla^2 u(x,y) &= -f(x,y) \label{poissonneu1} \\
	u(x,y)|_{\partial\Omega_D} &= 0 \label{poissonneu2} \\
	\frac{\partial u(x,y)}{\partial n}|_{\partial \Omega_N} &= g(x,y) \label{poissonneu3}
\end{align}
with the source term $f$ and exact solution $u$ given as above, and $g$ defined as
\begin{equation} \label{poissonneug}
	g(x,y) = 
	\begin{cases}
	-x \sin (2 \pi x^2), & \quad y=0 \text{ and } (x,y) \in \partial \Omega_N \\
	+y \sin (2 \pi y^2), & \quad x=0 \text{ and } (x,y) \in \partial \Omega_N \\
	\end{cases}
\end{equation}
The Dirichlet boundary surface is defined in polar coordinates by $\partial \Omega_D = \{(r, \theta) : r = 1, \theta \in [0, 3 \pi /2]\}$, and the Neumann boundary surface as $\partial \Omega_N = \{(r, \theta) : r \in [-1,0], \theta = 3 \pi /2\} \cup \{(r, \theta) : r \in [0,1], \theta = 0\} $.

\subsection{Boundary condition}

We now verify that (\ref{poissonneug}) is a solution to (\ref{poissonneu1}-\ref{poissonneu3}) at the boundary.

\begin{align}
	\frac{\partial u}{\partial n} &= \nabla u \cdot \vec{n} \\
	&= \left.\frac{\partial u}{\partial x}\right|_{y=0} \cdot
	\begin{bmatrix}
		0 \\
		-1
	\end{bmatrix}
	+ \left.\frac{\partial u}{\partial y}\right|_{x=0} \cdot
	\begin{bmatrix}
		1\\
		0
	\end{bmatrix}
	& \\
	& = 
	\begin{cases}
		-x \sin (2 \pi x^2), & \quad y=0 \text{ and } (x,y) \in \partial \Omega_N \\
		+y \sin (2 \pi y^2), & \quad x=0 \text{ and } (x,y) \in \partial \Omega_N \\
	\end{cases}
\end{align}

\subsection{Variational formulation}

When we introduce a test function $v\in V =\{v\in H^1 (\Omega) : v|_{\Omega_D} = 0\}$ to (\ref{poissonneu1}-\ref{poissonneu3}), integrate over $\Omega$ and then apply Green's formula, we end up with the equation
\begin{equation}
	-\iint_{\Omega} (\Delta u) v \d x \d y = \iint_{\Omega}\nabla u \cdot \nabla v \d x \d y -  \iint_{\partial \Omega} \frac{\partial u}{\partial n} v \d\gamma = \iint_{\Omega}fv \d x \d y.
\end{equation}
We now introduce both the Dirichlet and Neumann boundary conditions
\begin{equation}
	\iint_{\Omega}\nabla u \cdot \nabla v \d x \d y = \iint_{\Omega}fv \d x \d y + \iint_{\partial \Omega_D} \frac{\partial u}{\partial n} v \d\gamma + \iint_{\partial \Omega_N} \frac{\partial u}{\partial n} v \d\gamma.
\end{equation}
By imposing that the test function $v$ vanishes on $\Omega_D$, the equation becomes
\begin{equation}
	\iint_{\Omega}\nabla u \cdot \nabla v \d x \d y = \iint_{\Omega}fv \d x \d y + \iint_{\partial \Omega_N} g v \d\gamma. 
\end{equation}
The problem takes the form:
\begin{align}
	\text{Find $u \in V$ such that } a(u,v) &= F(v) \text{ for all $v \in V$, where} \\
	a(u,v) &=  \iint_{\Omega} \nabla u \cdot \nabla v \d x \d y, \\
	F(v) &= \iint_{\Omega}fv \d x \d y + \iint_{\partial \Omega_N} g v \d\gamma.
\end{align}


\subsection{Gauss quadrature}

The Neumann boundary condition is given as an integral and must be evaluated using Gaussian quadrature. We then modify our quadrature methods from the first section to solve line integrals in two dimensions, i.e. the method signature is \texttt{I = linequadrature1D(a,b,Nq,g)} where require $a\in \mathbb{R}^2$ and $b\in \mathbb{R}^2$.

\subsection{Implementation}

We change our code to solve the Neumann boundary value problem. The solution in the interior was the same as the analytical solution. Approximately, there is a very small error comparing the solution at the boundary, see figure \ref{vis:2dpoissonneu}.

\section{Poisson in 3D}

We now solve the problem (\ref{poissondirhom1}-\ref{poissondirhom2}) in three dimensions. We then generate a mesh, using the function \texttt{getBox}, which is similar to the written function in the previous section with the only difference is that spatial coordinates have one more component. The elements now require one more index to be described. The codes from the previous section are modified to deal with the tetrahedral elements in three dimensions with a new source term $f$, defined by
\begin{equation}
	f(x,y,z) = 12\pi^2\sin (2\pi x)\sin (2\pi y)\sin (2\pi z)
\end{equation}
and homogeneous Dirichlet boundary conditions $(u^D = 0)$. The problem has the exact solution
\begin{equation}
	u(x,y,z) = \sin (2\pi x)\sin (2\pi y)\sin (2\pi z).
\end{equation}

\chapter{Anisotropic Diffusion using Finite Element Method}

After applying the Finite Element Method to common and abstract cases, we chose to work on a diffusion equation which is applied in image processing. A typical problem in image processing is \emph{denoising}. One way to remove noise in a picture is to blur noisy areas while leaving edges unchanged. The linear heat equation can be used to blur an image, as the flow of heat can be interpreted as a flow of color on a plate. However, the linear heat equation does not preserve edges. In this project, we study the effects of a nonlinear PDE in image processing: the Perona-Malik anisotropic diffusion equation, that slows down the diffusion on domains where an edge has been detected. We explain our Finite Element solver for that problem and display various numerical experiments.

\section{What is a picture?}

In this section, we briefly describe some foundations of mathematical image processing. For this report, we shall assume that a \emph{continuous image} $u$ is an element of $L^\infty(\R^2)$, where each point in $\dom(u)$ maps to its corresponding grayscale value. Images typically have a compact support. When we take a picture, we generate a discretization of that functions $u$ which is an element of $\R^{n_1 \times n_2}$. Generally, we can take horizontal and vertical derivatives of images, when we assume $u \in L^\infty(\R^2) \cap C^1(\R^2$). These derivatives are numerically approximated by first order differences and can be interpreted as \emph{edges}, when they take relatively high values.

We also calculate also the \emph{peak-signal-to-noise ratio} (PSNR) and taking the initial image data without noise as a reference. The PSNR is a tool that allows us to measure the quality of our reconstruction.

Our test image is the \texttt{cameraman} image, which is built into MATLAB, see figure \ref{cameraman}. We add to this ground-truth image a Gaussian noise and consider the result as our given initial data.

\section{The Perona-Malik Equation and Finite Elements}

\subsection{Diffusion Equation} \label{sec:diffeqn}

The Perona-Malik equation \citep{perona1990} is a nonlinear diffusion equation that uses an inhomogeneous diffusivity coefficient,
\begin{equation} \label{pm}
	\frac{\partial u}{\partial t} = \nabla \cdot \left( g(\|\nabla u\|) \nabla u \right),
\end{equation}
where typical choices for $g$, often denoted as \emph{transfer function}, are
\begin{equation}
	g(\|\nabla u\|) = e^{-(\|\nabla u\|/K)^2}
\end{equation}
or
\begin{equation}
	g(\|\nabla u\|) = \frac{1}{1 + \left( \frac{\|\nabla u\|}{K}\right)^2}.
\end{equation}
Apparently, image areas with a small gradient experience strong blurring while edge areas remain unchanged. The original formulation (\ref{pm}) can lead to local backwards diffusion and become an ill-posed problem. Thus, we employ the so called \emph{regularized} Perona-Malik equation as proposed by \cite{catte1992}, where the edge indicator $\|\nabla u\|$ is replaced by $\|\nabla (G_\sigma \ast u)\|$, $G_\sigma \in C^\infty(\R^2)$ a smoothing kernel. The rest of this section relies on the definitions as given in \cite{handlovicova2002}. We begin with the regularized Perona-Malik equation
\begin{equation} \label{pmreg}
    \frac{\partial u}{\partial t} = \nabla \cdot \left( g\left(\left\|\nabla (G_{\sigma} \ast u)\right\|\right) \nabla u \right).
\end{equation}

The function $u = u(t,x)$ is defined in $I \times \Omega$. We assume $I = [0, T]$ and $\Omega \ssq \R^2$ to a bounded rectangular domain. The parameter $t$ can be seen as abstract scaling parameter \citep[p. 219]{handlovicova2002}. We equip (\ref{pmreg}) with Neumann boundary conditions
\begin{align}
	\frac{\partial u}{\partial \nu} &= 0 & \text{on } I \times \partial \Omega, \\
	u(0,x) &= {u^0}(x) & \text{in } \Omega.
\end{align}

Further, we assume $g: \R^+ \rightarrow \R^+$ to be a smooth, nonincreasing function, $g(0)=1$ and $\lim_{s \rightarrow \infty} g(s) = 0$. For the smoothing kernel, we assume $G_\sigma \in C^\infty(\R^2)$, $\int_\R G_\sigma \d x = 1$, $\int_\R |G_\sigma| \d x < \infty$ and that $G_\sigma$ converges to the Dirac measure if $\sigma \to 0$. Finally, let $u^0 \in L^\infty(\Omega)$. As described in \cite{handlovicova2002}, we do not compute the convolution $G_{\sigma} \ast u$, but use isotropic diffusion, i.e. $g \equiv 1$, in order to obtain a blurred version $u_iso$ of the image. The PDE simplifies in this case to
\begin{equation} \label{pmiso}
	\frac{\partial u_\iso}{\partial t} = \Delta u_\iso.
\end{equation}

\subsection{Finite Element Method} 

We do not present the full derivation of the Finite Element procedure in this report, but refer to the lecture and the paper from \cite{handlovicova2002}. The linear isotropic solution $u_\iso$ is used to compute the diffusion coefficients $g\left(\left\|\nabla (G_{\sigma} \ast u)\right\|\right)$. We assume these coefficients as fixed in scale, i.e. we numerically compute
\begin{equation}
	\frac{\partial u_\ani}{\partial t} = \nabla \cdot (\underbrace{g(\|\nabla \underbrace{(G_{\sigma} \ast u^0)}_{=u_\iso}\|)}_\text{const.} \nabla u_\ani).
\end{equation}

We use implicit Euler in scale and obtain the weak formulations
\begin{align}
	\int_\Omega u_\iso v \d x + \sigma \int_\Omega \nabla u_\iso \nabla v \d x &= \int_\Omega u^0 v \d x, \\
	\int_\Omega u_\ani v \d x + \tau \int_\Omega g(\|\nabla u_\iso\|) \nabla u_\ani \nabla v \d x &= \int_\Omega u^0 v \d x.
\end{align}

We consider a triangulation $\T_h$ of $\Omega$ and a nodal basis of continuous, piecewise linear functions $\phi_j$, satisfying $\phi_j(x_i) = \delta_{ji}$ for all nodes $x_i$ of $\T_h$, $i,j=1,...,M$. The initial value $u^0$ and the unknown functions $u_\iso$ and $u_\ani$ are represented by
\begin{align}
	u^0_h & = \sum_{i=1}^{M} u^0_i \phi_i, \\
	u_{\iso, h} &= \sum_{i=1}^{M} u_{\iso, i} \phi_i, \\
	u_{\ani, h} &= \sum_{i=1}^{M} u_{\ani, i} \phi_i,
\end{align}
with the unknown scalar coefficients $u^0_i, u_{\iso, i}, u_{\ani, i} \in \R$, $i=1,...,M$. With the Ritz-Galerkin method, we obtain
\begin{align}
	\sum_{i=1}^{M} \left( \int_\Omega \phi_i \phi_j \d x + \sigma \int_\Omega \nabla \phi_i \nabla \phi_j \d x \right) u_{\iso, i} &= \sum_{i=1}^{M} \left( \int_\Omega \phi_i \phi_j \d x \right) u^0_i, \\
	\sum_{i=1}^{M} \left( \int_\Omega \phi_i \phi_j \d x + \tau \int_\Omega g(\|\nabla u_{\iso,h}\|) \nabla \phi_i \nabla \phi_j \d x \right) u_{\ani, i} &= \sum_{i=1}^{M} \left( \int_\Omega \phi_i \phi_j \d x \right) u^0_i.
\end{align}
This can also be written as two linear systems
\begin{align}
	[M + \sigma A(1)] \begin{bmatrix}u_{\iso,1}\\\vdots\\u_{\iso,M}\end{bmatrix} &= M \begin{bmatrix}u^0_1\\\vdots\\u^0_M\end{bmatrix}, \\
	[M + \tau A(g(\|\nabla u_{\iso,h}\|))] \begin{bmatrix}u_{\ani,1}\\\vdots\\u_{\ani,M}\end{bmatrix} &= M \begin{bmatrix}u^0_1\\\vdots\\u^0_M\end{bmatrix},
\end{align}
where $M_{j,i} = \int_\Omega \phi_i \phi_j \d x$ is the so-called \emph{mass matrix} and $A(w)_{j,i} = \int_\Omega w \nabla \phi_i \nabla \phi_j \d x$ is the \emph{stiffness matrix}. The parameters $\sigma$ and $\tau$ denote the scale parameter for the two diffusion processes.

\section{Numerical experiments}

\subsection{First steps} 

We performed several numerical simulations of the Perona-Malik diffusion using the Finite Element Method on 2D images. Our first sample is the \texttt{cameraman} picture, see figure \ref{cameraman}. We just write $u^0 \in \R^{n_1 \times n_2}$ from now on, to denote the initial data, where $n_1, n_2 \in \N$ denote the image dimensions.

\paragraph{Triangular Mesh}

A naive approach for grid generation is to identify each pixel in the image with a node on the grid. The obtained squares are crossed diagonally to obtain triangles. This procedure yields a grid with $\O(n_1 n_2)$ nodes and $\O(2 n_1 n_2)$ elements. It turns out handy to use the matrix indices as spatial coordinates, i.e. we set $\Omega = [1,n_1] \times [1,n_2]$ and the triangulation nodes $x_{i,j} = (i,j)$ for $i=1,...,n_1$, $j=1,...,n_2$, see figure \ref{gridptpix}.
\begin{figure}[h]
	\centering
	\begin{tabular}{|c|c|c|}
		\hline		
		$(1,1)$ & $\hdots$ & $(1,n_2)$ \\ \hline
		$\vdots$ & $\ddots$ & $\vdots$ \\ \hline
		$(n_1,1)$ & $\hdots$ & $(n_1,n_2)$ \\ \hline
	\end{tabular}
	\caption{Matching of grid points and pixels.}
	\label{gridptpix}
\end{figure}

We realized this grid generation procedure with the function \texttt{getSquareTri} that takes the dimensions of the picture \texttt{nx} as parameters and returns \texttt{p}, a list of node coordinates, \texttt{tri}, a list of all triangles, denoted by their corner node ids, and \texttt{edge}, the set of all boundary line segments, denoted by the node ids of their corresponding start and ending points.

\paragraph{Algorithm}

The first program we tested is basically a modified version of Part 1 of the project. First, we compute the grid and pass the following arguments to \texttt{pm\_tri}:
\begin{itemize}
    \item
    \texttt{u}, the initial data,
    
    \item 
    \texttt{tri, p, edge}, the output of \texttt{getSquareTri} or another grid generator (see section
     \ref{gridgen}),
     
    \item
    the scale parameters \texttt{sigma} and \texttt{tau},
    
    \item
    the transfer function \texttt{g} as a function handle.
\end{itemize}
The function returns the followings values:
\begin{itemize}
    \item 
    \texttt{u\_ani}, the anisotropic solution,
    \item
    \texttt{A\_iso}, the isotropic stiffness matrix,
    \item
    \texttt{M}, the mass matrix,
    \item
    \texttt{u\_iso}, the isotropic solution,
    \item
    \texttt{g\_ani}, the diffusivity on the elements,
    \item
    \texttt{A\_ani}, the anisotropic stiffness matrix.
\end{itemize}
The whole procedure can be described in the following way:
\begin{enumerate}
	\item
	\textbf{Grid generation (GG)}
	\item
	\textbf{Isotropic diffusion (ID)}
	\begin{enumerate}	
		\item 
		Initialization of $M$, $A_\iso$, $N_q$.
		\item 
		For each triangle (visited once):
		\begin{itemize}
			\item
			Get the node id to identify points and basis functions.
			\item 
			Get the coordinates of the nodes \texttt{p1,p2,p3}.
			\item 
			Compute the functions $\phi_i$ ($i=1,2,3$) that land in the triangle.
			\item 
			For $i,j=1,2,3$:
			\begin{itemize}
				\item
				Define $f_\iso = \nabla \phi_i \nabla \phi_j$, a constant function.
				\item
				Update the isotropic stiffness matrix.\\
				\texttt{A\_iso(nodeID(i),nodeID(j)) += quadrature2D(p1,p2,p3,Nq,f\_iso);}
				\item
				Compute $f_\mass = \phi_i \phi_j$, a quadratic function.
				\item
				Update the mass matrix. \\
				\texttt{M(nodeID(i),nodeID(j)) += quadrature2D(p1,p2,p3,Nq,f\_mass);}
			\end{itemize}
		\end{itemize}
		\item 
		Solve the linear system \texttt{u\_iso = (M + sigma * A\_iso) \bslash\ (M * u)}.
	\end{enumerate}
	\item
	\textbf{Compute the diffusion coefficients (DC)}
	\begin{enumerate}
		\item 
		Initialization of the gradient matrix $d$.
		\item 
		For each triangle \texttt{k} (visited once):
		\begin{itemize}
			\item
			Get the node id to identify points and basis functions.
			\item 
			Get the coordinates of the nodes \texttt{p1,p2,p3}.
			\item 
			Compute the functions $\phi_i$ ($i=1,2,3$) that land in the triangle.
			\item
			For $i = 1,2,3$:
			\begin{itemize}
				\item
				Compute the local gradient $z = u_{\iso,i} \nabla \phi_i$.
				\item
				Update \texttt{d(k) += z}.
			\end{itemize}
		\end{itemize}
		\item 
		Evaluate the transfer function: \texttt{g\_ani = g(pointwise\_norm(d))}.
	\end{enumerate}
	\item
	\textbf{Anisotropic diffusion (AD)}
	\begin{enumerate}
		\item 
		Initialization of $A_\ani$.
		\item 
		For each triangle \texttt{k} (visited once):
		\begin{itemize}
			\item
			Get the node id to identify points and basis functions.
			\item 
			Get the coordinates of the nodes \texttt{p1,p2,p3}.
			\item 
			Compute the functions $\phi_i$ ($i=1,2,3$) that land in the triangle.
			\item 
			For $i,j=1,2,3$:
			\begin{itemize}
				\item
				Define $f_\ani = g_k \nabla \phi_i \nabla \phi_j$, a constant function.
				\item
				Update the anisotropic stiffness matrix.\\
				\texttt{A\_ani(nodeID(i),nodeID(j)) += quadrature2D(p1,p2,p3,Nq,f\_ani);}
			\end{itemize}
			
		\end{itemize}
		\item 
		Solve the linear system \texttt{u\_ani = (M + tau * A\_ani) \bslash\ (M * u)}.
	\end{enumerate}
\end{enumerate}

\paragraph{Visualization} 

We display our results by the following four pictures (in direction of reading):
\begin{enumerate}
	\item 
	The first picture is the initial picture.
	\item
	The second picture visualizes the used grid.
	\item
	The third picture is a visualization of the anisotropic solution $u_\ani$ on the grid using \texttt{trisurf}. We used the \emph{interpolated shading} in MATLAB to give a smooth result.
	\item
	The fourth picture represents the anisotropic solution $u_\ani$ interpolated on a regular meshgrid. We used the function \texttt{griddata} and the method \texttt{natural} for the interpolation.
\end{enumerate}
The different approaches for the visualization of $u_\ani$ become important when we use unstructured grids, see section \ref{gridgen}.

\paragraph{Results}

Our visual impression is that the image noise is removed while the edges are preserved. Table \ref{res:firsttry} summarizes the first numerical experiment.

\begin{table}[h]
	\centering
	\begin{tabular}{|ll}
		Image data & \texttt{cameraman} ($128 \times 128$ pixels) \\
		Grid generation & \texttt{getSquareTri} \\
		Num. of nodes & 16384\\
		Num. of elements & 32258\\
		Parameters & $\sigma=0.5$, $\tau=0.8$, $g(x) = e^{-(12 x)^2}$ \\
		Runtime GG & 0.43145s \\
		Runtime ID & 52.7717s \\
		Runtime DC & 0.68412s \\
		Runtime AD & 27.6838s\\
		PSNR & 29.0056 \\
		Visualization & See figure \ref{vis:firsttry}. \\
	\end{tabular}
	\caption{Results of first numerical experiment}
	\label{res:firsttry}
\end{table}

\subsection{Efficient implementation}

\paragraph{Method}

In order to make a more efficient implementation, we took the following measures:

\begin{itemize}
    \item
    Precomputation and storage of triangle areas, basis function coefficients and triangle midpoints.
    \item 
    Enforce more use of vector notation.
    \item 
    Removal of the function call of \texttt{quadrature2D} and an anonymous function call. Instead, we used the precomputed values to get the triangular integral directly.
\end{itemize}

\paragraph{Results}

The program obtained is faster, see table \ref{res:efficient}, were the precomputation time is denoted as \textit{Runtime PR}. We shall use this version of the code for the further examples.

\begin{table}[h]
	\centering
	\begin{tabular}{|ll}
		Image data & \texttt{cameraman} ($128 \times 128$ pixels) \\
		Grid generation & \texttt{getSquareTri} \\
		Num. of nodes & 16384\\
		Num. of elements & 32258\\
		Parameters & $\sigma=0.5$, $\tau=0.8$, $g(x) = e^{-(12 x)^2}$ \\
		Runtime GG & 0.43546s \\
		Runtime PR & 0.77099s \\
		Runtime ID & 5.4611s \\
		Runtime DC & 0.1238s \\
		Runtime AD & 2.3429s \\
		PSNR & 28.6091 \\
		Visualization & See figure \ref{vis:efficient}.\\
	\end{tabular}
	\caption{Results of efficiency-improved numerical experiment}
	\label{res:efficient}
\end{table}

\subsection{Grid generation strategies} \label{gridgen}

\subsubsection{Diagonal swapping}
\paragraph{Method}
In order to fit the edges of the image better, we decided to implement an improved grid generation strategy by swapping the diagonals of some triangles. For each square that shall be divided in two triangles by \texttt{getSquareTri}, we compare the terms $|u_\text{top left} - u_\text{bottom right}|$ and $|u_\text{top right} - u_\text{bottom left}|$. If the first term is bigger than the second term, we split the square along the line through $x_\text{top right}$ and $x_\text{bottom left}$. Otherwise, we split the square along the line through $x_\text{top left}$ and $x_\text{bottom right}$. This behavior is implemented in \texttt{getSquareTri\_swp}.

\paragraph{Results}

When we compare the results with the first grid, we notice that the new grid seems to be more adapted to the image. Table \ref{res:diagswp} summarizes.

\begin{table}[h]
	\centering
	\begin{tabular}{|lll}
		Image data & \multicolumn{2}{c}{\texttt{rhombus} ($40 \times 40$ pixels)} \\
		Grid generation & \texttt{getSquareTri} & \texttt{getSquareTri\_swp} \\
		Num. of nodes & \multicolumn{2}{c}{1600} \\
		Num. of elements & \multicolumn{2}{c}{3042} \\
		Parameters & \multicolumn{2}{c}{$\sigma=0.5$, $\tau=0.8$, $g(x) = e^{-(12 x)^2}$} \\
		Runtime GG & 0.009271s & 0.008785s \\
		Runtime PR & 0.078194s & 0.07624s \\
		Runtime ID & 0.33618s & 0.33155s \\
		Runtime DC & 0.013159s & 0.012268s\\
		Runtime AD & 0.13707s & 0.13583s\\
		PSNR & 27.0748 & 27.1408 \\
		Visualization & See figure \ref{vis:diagswp1}. & See figure \ref{vis:diagswp2}. \\
	\end{tabular}
	\caption{Results of diagonal swapping}
	\label{res:diagswp}
\end{table}

\subsubsection{Using variance information}

\paragraph{Method}

Intuitively speaking, it is not necessary to use a high resolution grid on image areas with few variation. However, the use of a fine grid is indicated in areas with high variation such as corner and edge regions. In order to use less elements in the smooth areas, and more elements in the edge areas we decided to implement a new grid generation strategy by using the \emph{variance} (as known from statistics) as criterion for the local coarseness of the grid.

We implement a recursive procedure \texttt{getVarigrid} as follows: A rectangular image portion is considered to contain enough information for grid refinement if the variance of the image portion lies above a certain threshold. If this is the case, the center of the rectangle is added as new node to the triangulation and the four resulting rectangles are analyzed recursively. We start with the whole image as initial image portion and its corner nodes as initial nodes for the mesh. The triangulation of the so generated point set is computed by MATLAB using built-in \texttt{delaunayTriangulation} procedure.

\paragraph{Further improvements}

As improvement, we added a \emph{corner value criterion} to the procedure. It also allows to perform a split if the absolute difference of any of two corner values are above a certain threshold. Finally, we set a minimal depth and maximal depth for the number of recursive function calls in order to ensure a minimal and maximal grid fineness. Because we have to deal with noisy data, there is always a certain amount of noise-induced variance and the variance criterion can be misleading. Our suggestion to overcome this issue is to preprocess the image with a simple Gaussian filter, such as MATLAB's built-in \texttt{imgaussfilt} routine.

\paragraph{Results}

The result seems satisfying regarding the few numbers of nodes and elements that still yield a good fit of the image data. The performance of the algorithm is improved by the reduced number of nodes and elements. Table \ref{res:varigrid} summarizes this experiment.

\begin{table}[h]
	\centering
	\begin{tabular}{|ll}
		Image data & \texttt{cameraman} ($256 \times 256$ pixels)\\
		Grid generation & \texttt{getVarigrid} \\
		Num. of nodes & 6470 \\
		Num. of elements & 12866 \\
		Parameters & $\sigma=0.5$, $\tau=0.8$, $g(x) = e^{-(12 x)^2}$, \\
		& $\sigma_\text{imgaussfilt}=2$, $\sigma^2_\text{min}=0.0001$, $d_\text{corner}=0.2$, \\
		& $n_\text{mindepth}=4$, $n_\text{maxdepth}=50$ \\
		Runtime GG & 0.47358s \\
		Runtime PR & 0.31019s \\
		Runtime ID & 2.1717s \\
		Runtime DC & 0.05034s \\
		Runtime AD & 0.95878s \\
		PSNR & 23.9248 \\
		Visualization & See figure \ref{vis:varigrid}. \\
	\end{tabular}
	\caption{Results of variance based grid generation}
	\label{res:varigrid}
\end{table}

\subsubsection{Gradient information and random node sampling}

\paragraph{Method}

An other way to capture image areas with \emph{relevant} information such as corners and edge is the use of gradient information. Intuitively speaking, image domains with a small gradient contain few relevant information while image domains with a high gradient are important for the visual image perception. This idea motivates the following grid generation strategy \texttt{getGradgrid}: We use MATLAB's matrix convolution \texttt{conv2} in order to compute the vertical and horizontal image derivatives. We then normalize the norm of the obtained gradients to values between $0$ and $1$. These values are used as probabilities for each pixel of the image to become a node in the grid. The random sample of grid points is again transformed by \texttt{delaunayTriangulation} to a triangular mesh.

\paragraph{Further improvements}

In order to prevent image noise to bias the gradient values, we apply again Gaussian filtering as a preprocessing step to the image before the grid is generated. We further allow to use a transfer function to map the normalized gradient norms to probability values.

\paragraph{Results}

The use of \texttt{getGradgrid} creates a very smooth and \emph{cartoon-like} image. We think this comes from the fact that gradient information is taken twice into account: once in the grid generation and once when solving the Perona-Malik equation. This sets a stronger focus on edge preservation and smoothing of already smooth areas. Again, a smaller number of nodes have to be used. Table \ref{res:gradgrid} summarizes this experiment.

\begin{table}[h]
	\centering
	\begin{tabular}{|lll}
		Image data & \multicolumn{2}{c}{\texttt{cameraman} ($256 \times 256$ pixels)} \\
		Grid generation & \multicolumn{2}{c}{\texttt{getGradgrid}} \\
		Num. of nodes & \multicolumn{2}{c}{6610} \\
		Num. of elements & \multicolumn{2}{c}{13158} \\
		Parameters & \multicolumn{2}{c}{$\sigma=0.5$, $g(x) = e^{-(12 x)^2}$} \\
		& \multicolumn{2}{c}{$\sigma_\text{imgaussfilt}=2$, $g_\text{transfer}(x) = x$}\\
		$\tau=$ & 0.8 & 1.4 \\
		Runtime GG & \multicolumn{2}{c}{0.050293s} \\
		Runtime PR & 0.32198s & 0.3245s \\
		Runtime ID & 2.3301s & 2.3281s\\
		Runtime DC & 0.051472s & 0.052429s \\
		Runtime AD & 1.0208s & 1.0213s \\
		PSNR & 23.1113 & 23.399 \\
		Visualization & See figure \ref{vis:gradgrid1}. & See figure \ref{vis:gradgrid2}. \\
	\end{tabular}
	\caption{Results of gradient based grid generation}
	\label{res:gradgrid}
\end{table}

\subsection{Parameter modification}

\subsubsection{Anisotropic scale $\tau$}

We want to see the diffusion on the picture for different values of $\tau$. We compare the PNSR of different scales and present the results in table \ref{res:taus}. Notably, we find an optimal PSNR around $\tau = 0.5$.

\begin{table}[h]
	\centering
	\begin{tabular}{|lllllllllll}
		Image data & \multicolumn{10}{c}{\texttt{cameraman} ($256 \times 256$ pixels)} \\
		Grid generation & \multicolumn{10}{c}{\texttt{getVarigrid}} \\
		Num. of nodes & \multicolumn{10}{c}{6610} \\
		Num. of elements & \multicolumn{10}{c}{13158} \\
		Parameters & \multicolumn{10}{c}{$\sigma=0.5$, $g(x) = e^{-(12 x)^2}$,} \\
		& \multicolumn{10}{c}{$\sigma_\text{imgaussfilt}=2$, $\sigma^2_\text{min}=0.0001$, $d_\text{corner}=0.2$,} \\
		& \multicolumn{10}{c}{$n_\text{mindepth}=4$, $n_\text{maxdepth}=50$} \\
		$\tau =$ & 0 & 0.5 & 1 & 5 & 10 & 50 & 100 & 500 & 1000 & 5000\\
		PSNR & 23.9 & 24.1 & 24.0 & 23.4 & 23.0 & 21.3 & 20.4 & 18.2 & 17.1 & 14.2 \\
		Visualization in fig. &  \ref{vis:taus01} &  \ref{vis:taus02} &  \ref{vis:taus03} &  \ref{vis:taus04} &  \ref{vis:taus05} &  \ref{vis:taus06} &  \ref{vis:taus07} &  \ref{vis:taus08} &  \ref{vis:taus09} &  \ref{vis:taus10} \\
	\end{tabular}
	\caption{Results for different values of $\tau$}
	\label{res:taus}
\end{table}

\subsubsection{Transfer function}

The modification of the transfer function $g$ can change the way, the diffusion performs on the image. We tested several transfer functions, that satisfy the conditions stated in section \ref{sec:diffeqn}. Namely, we parametrize
\begin{equation}
	g(x) = g(x; K)= e^{-(Kx)^2},
\end{equation}
and present the results in table \ref{res:gs}.

\begin{table}[h]
	\centering
	\begin{tabular}{|lllll}
		Image data & \multicolumn{4}{c}{\texttt{cameraman} ($256 \times 256$ pixels)} \\
		Grid generation & \multicolumn{4}{c}{\texttt{getVarigrid}} \\
		Num. of nodes & \multicolumn{4}{c}{} \\
		Num. of elements & \multicolumn{4}{c}{} \\
		Parameters & \multicolumn{4}{c}{$\sigma=0.5$, $\tau=1.5$, $g(x) = e^{-(Kx)^2}$,} \\
		& \multicolumn{4}{c}{$\sigma_\text{imgaussfilt}=2$, $\sigma^2_\text{min}=0.0001$, $d_\text{corner}=0.2$,} \\
		& \multicolumn{4}{c}{$n_\text{mindepth}=4$, $n_\text{maxdepth}=50$} \\
		$K =$ & -100 & -10 & -1 & -0.1 \\
		PSNR & 24.35 & 23.20 & 21.32 & 21.30 \\
		Visualization &  \multicolumn{4}{c}{See figure \ref{vis:gs}.} \\
	\end{tabular}
	\caption{Results for different transfer functions $g$.}
	\label{res:gs}
\end{table}

According to the comparison between the PSNR values, $K=100$ seems to be the best choice, the picture keeps many details but is still noisy. The choice $K=10$ seems to give a good result with a smooth image. Generally, the choice of the transfer function depends on the application (e.g. deleting the noise or keeping the details).

\subsubsection{Interpolation method}

We tried to modify the visualization method of our results by changing the interpolation method for the anisotropic solution, MATLAB offers \texttt{natural}, \texttt{nearest}, \texttt{linear}, \texttt{cubic}, and \texttt{v4}. There was only a slight difference between most of the method, but we found \texttt{natural} the most appropriate.

\subsubsection{Parameters of grid generation}

The procedures \texttt{getVarigrid} and \texttt{getGradgrid} procedures require a even broader set of parameter choices. We can modify the parameters e.g. in order to increase the numbers of nodes and elements. For the variance based grid generation, we decrease the required \textit{minimum variance} for a split, such that more nodes can be selected, see table \ref{res:minvars}. For the gradient based grid generation, we modify the transfer function $g_\text{transfer}$, see table \ref{res:transfers}. 

\begin{table}[h]
	\centering
	\begin{tabular}{|llll}
		Image data & \multicolumn{3}{c}{\texttt{cameraman} ($256 \times 256$ pixels)} \\
		Grid generation & \multicolumn{3}{c}{\texttt{getVarigrid}} \\
		Num. of nodes & 2970 & 6510 & 12927 \\
		Num. of elements & 5923 & 12945 & 25660 \\
		Parameters & \multicolumn{3}{c}{$\sigma=0.5$, $\tau=1.5$, $g(x) = e^{-(12 x)^2}$,} \\
		& \multicolumn{3}{c}{$\sigma_\text{imgaussfilt}=2$, $d_\text{corner}=0.2$,} \\
		& \multicolumn{3}{c}{$n_\text{mindepth}=4$, $n_\text{maxdepth}=50$} \\
		$\sigma^2_\text{min}=$ & $10^{-3}$ & $10^{-4}$ & $10^{-5}$ \\
		PSNR & 22.23 & 23.58 & 24.49 \\
		Visualization &  \multicolumn{3}{c}{See figure \ref{vis:minvars}.} \\
	\end{tabular}
	\caption{Results for different values of $\sigma^2_\text{min}$ in \texttt{getVarigrid}}
	\label{res:minvars}
\end{table}

\begin{table}[h]
	\centering
	\begin{tabular}{|llll}
		Image data & \multicolumn{3}{c}{\texttt{cameraman} ($256 \times 256$ pixels)} \\
		Grid generation & \multicolumn{3}{c}{\texttt{getGradgrid}} \\
		Num. of nodes & 6998 & 2410 & 1277 \\
		Num. of elements & 13940 & 4808 & 2546 \\
		Parameters & \multicolumn{3}{c}{$\sigma=0.5$, $\tau=1.5$, $g(x) = e^{-(12 x)^2}$} \\
		& \multicolumn{3}{c}{$\sigma_\text{imgaussfilt}=2$} \\
		$g_\text{transfer}$ & $x \mapsto x$ & $x \mapsto x^2$ & $x \mapsto x^3$ \\
		PSNR & 23.26 & 21.11 & 19.17 \\
		Visualization &  \multicolumn{3}{c}{See figure \ref{vis:transfers}.} \\
	\end{tabular}
	\caption{Results for different functions $g_\text{transfer}$ in \texttt{getGradgrid}}
	\label{res:transfers}
\end{table}

\subsection{Quadrilateral elements}

\paragraph{Method}

Instead of using triangular elements, we thought, we could use square element and exploit the regular structure of image data. We implemented a Finite Element algorithm using squares instead of the triangles. We used analytical computations to make the code faster by computing: 

\begin{itemize}
    \item 
    The basis functions $\phi_i$ and their value on the integration point.
    \item 
    The integrations by the midpoint rule.
\end{itemize}
The precomputation is done by a MATLAB script that handles symbolic variables and auto-generates the correct MATLAB code for the Finite Element procedure. The visualization shows: 
\begin{enumerate}
\item 
The initial noisy image
\item 
The isotropic solution 
\item 
The anisotropic solution
\end{enumerate}

\paragraph{Results}

We notice a \emph{checkerboard effect} (see figure \ref{vis:gs}) on the visualization of the anisotropic solution. \cite{shukla2013} explain that the checkerboard effect is a common problem of the finite element method. One way to resolve it can be to use higher order Finite Element which leads to a computationally heavier program. Other methods like the \emph{perimeter control technique}, or the \emph{patch technique} are proposed in the paper. We did not continue to work with quadrilateral elements. We summarize this numerical experiment in table \ref{res:tet}.

\begin{table}[h]
	\centering
	\begin{tabular}{|ll}
		Image data & \texttt{cameraman} ($128 \times 128$ pixels) \\
		Grid generation & \texttt{getSquareTet} \\
		Num. of nodes & 16384 \\
		Num. of elements & 16129 \\
		Parameters & $\sigma=0.5$, $\tau=1$, $g(x) = e^{-(12 x)^2}$ \\
		Runtime GG & 0.16881s \\
		Runtime ID & 6.6781s \\
		Runtime DC & 0.005166s \\
		Runtime AD & 1.929s \\
		PSNR & -- \\
		Visualization & See figure \ref{vis:tet}. \\
	\end{tabular}
	\caption{Results for quadrilateral elements}
	\label{res:tet}
\end{table}


\section{Outlook}

Our work can be applied in several fields that involve image processing. In the medical field, image processing is often used to exact information from e.g. ultrasound imaging or Magnetic resonance imaging (MRI). The goal is for example to distinguish the layers of different tissues in order to find a tumor. Our algorithm could help to denoise such medical images and facilitate their interpretation for human or machine vision. In future work, our algorithm could be applied on 3D images as well.

From the mathematical perspective, it could be useful to develop higher order Finite Element method and increase the accuracy. It should be taken into account that image data is often in high resolution and the application of Finite Elements can become costly. However, the usage of advanced grid generation strategies can help to reduce the computational complexity, as we have shown in this report.

The treatment of color images can be relevant as well. A naive approach here is to use our greyscale Perona-Malix implementation on the (typically three) color layers of the color image. The resulting color fringes can be reduced by employing different color encoding schemes such as the \emph{hue-saturation-value} (HSV) color representation \citep{bredies2010}. The use of multiple coupled PDEs can be another approach to treat color images \citep{bredies2010}.

\chapter{Conclusion}

In the first part of the report, we have examined the Poisson equation from various perspectives. In the second part of this report, we showed how to implement the Perona-Malik diffusion equation using Finite Element Methods with an efficient algorithm. We also showed how to reduce the numbers of elements and nodes (so the algorithm's speed) by focusing on the important image areas (edges for example) by using different methods (variance and gradient). The comparison between the different methods leads to choices depending on the application chosen (medical data, picture restoration, etc.), since different factors have to be taken into account (quality, speed, smoothness). 

\bibliography{literature}

\appendix

\chapter{Figures for Part 1}

\begin{figure}
	\includegraphics[width=\textwidth]{../out/test_poisson2d_dirichlet.png}
	\caption{Solution of the 2D Poisson equation with homogeneous Dirichlet boundary conditions, $n=50, 500, 1000$, numerical solution (left column) and analytical solution (right column)}
	\label{vis:2dpoissondir}
\end{figure}

\begin{figure}
	\includegraphics[width=\textwidth]{../out/test_poisson2d_neumann.png}
	\caption{Solution of the 2D Poisson equation with mixed boundary conditions, $n=50, 500, 1000$, numerical solution (left column) and analytical solution (right column)}
	\label{vis:2dpoissonneu}
\end{figure}

\chapter{Figures for Part 2}

\begin{figure}
	\centering
	\includegraphics{cameraman.jpg}
	\caption{The \texttt{cameraman} picture}
	\label{cameraman}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{../out/report_firsttry.png}
	\caption{Visualization of first numerical experiment}
	\label{vis:firsttry}
\end{figure}

\begin{figure}
	\includegraphics[width=\textwidth]{../out/report_efficient.png}
	\caption{Visualization of efficiency-improved numerical experiment}
	\label{vis:efficient}
\end{figure}

\begin{figure}
	\includegraphics[width=\textwidth]{../out/report_diagswp1.png}
	\caption{Visualization of the \textit{rhombus} denoising without diagonal swap}
	\label{vis:diagswp1}
\end{figure}

\begin{figure}
	\includegraphics[width=\textwidth]{../out/report_diagswp2.png}
	\caption{Visualization of the \textit{rhombus} denoising with diagonal swap}
	\label{vis:diagswp2}
\end{figure}

\begin{figure}
	\includegraphics[width=\textwidth]{../out/report_varigrid.png}
	\caption{Visualization of the \textit{varigrid} experiment}
	\label{vis:varigrid}
\end{figure}

\begin{figure}
	\includegraphics[width=\textwidth]{../out/report_gradgrid1.png}
	\caption{Visualization of the \textit{gradgrid} experiment with $\tau = 0.8$}
	\label{vis:gradgrid1}
\end{figure}

\begin{figure}
	\includegraphics[width=\textwidth]{../out/report_gradgrid2.png}
	\caption{Visualization of the \textit{gradgrid} experiment with $\tau = 1.4$}
	\label{vis:gradgrid2}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[]{../out/report_taus01.png}
	\caption{Variation of scale, here $\tau = 0$}
	\label{vis:taus01}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[]{../out/report_taus02.png}
	\caption{Variation of scale, here $\tau = 0.5$}
	\label{vis:taus02}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[]{../out/report_taus03.png}
	\caption{Variation of scale, here $\tau = 1$}
	\label{vis:taus03}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[]{../out/report_taus04.png}
	\caption{Variation of scale, here $\tau = 5$}
	\label{vis:taus04}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[]{../out/report_taus05.png}
	\caption{Variation of scale, here $\tau = 10$}
	\label{vis:taus05}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[]{../out/report_taus06.png}
	\caption{Variation of scale, here $\tau = 50$}
	\label{vis:taus06}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[]{../out/report_taus07.png}
	\caption{Variation of scale, here $\tau = 100$}
	\label{vis:taus07}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[]{../out/report_taus08.png}
	\caption{Variation of scale, here $\tau = 500$}
	\label{vis:taus08}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[]{../out/report_taus09.png}
	\caption{Variation of scale, here $\tau = 1000$}
	\label{vis:taus09}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[]{../out/report_taus10.png}
	\caption{Variation of scale, here $\tau = 5000$}
	\label{vis:taus10}
\end{figure}

\clearpage

\begin{figure}
	\centering
	\includegraphics[]{../out/report_gs.png}
	\caption{Results for different transfer functions $g$ ($K = -100, -10, -1, -0.1$, in reading direction), see table \ref{res:gs}}
	\label{vis:gs}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[]{../out/report_minvars.png}
	\caption{Different minimal variance ($\sigma^2_\text{min} = 10^{-3}, 10^{-4}, 10^{-5}$, from left to right) in \texttt{getGradgrid} (top row) with corresponding solution (bottom row).}
	\label{vis:minvars}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[]{../out/report_transfers.png}
	\caption{Results for different functions $g_\text{transfer}$ in \texttt{getGradgrid}, see table \ref{res:transfers}}
	\label{vis:transfers}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[]{../out/report_tet.png}
	\caption{Results for quadrilateral elements with checkerboard effect}
	\label{vis:tet}
\end{figure}

\end{document}
